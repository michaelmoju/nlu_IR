{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format = '%(asctime)s ***%(levelname)s*** [%(name)s:%(lineno)s] - %(message)s',\n",
    "                    datefmt = '%Y/%m/%d %H:%M:%S',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucene\n",
    "from org.apache.lucene.analysis.cn.smart import SmartChineseAnalyzer\n",
    "from org.apache.lucene.store import RAMDirectory, FSDirectory\n",
    "from org.apache.lucene.index import IndexWriter, IndexWriterConfig, IndexReader, DirectoryReader\n",
    "from org.apache.lucene.document import Document, StringField, TextField, Field\n",
    "from org.apache.lucene.search import IndexSearcher\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.search.similarities import ClassicSimilarity, BM25Similarity\n",
    "from org.apache.pylucene.search.similarities import PythonClassicSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSimilarity(PythonClassicSimilarity):\n",
    "\n",
    "    def lengthNorm(self, numTerms):\n",
    "        return 1.0\n",
    "\n",
    "    def tf(self, freq):\n",
    "        return freq\n",
    "\n",
    "    def sloppyFreq(self, distance):\n",
    "        return 2.0\n",
    "\n",
    "    def idf(self, docFreq, numDocs):\n",
    "        return 1.0\n",
    "\n",
    "    def idfExplain(self, collectionStats, termStats):\n",
    "        return Explanation.match(1.0, \"inexplicable\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySimilarity = ClassicSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChineseRamIndexer:\n",
    "    def __init__(self):\n",
    "        lucene.initVM()\n",
    "        indexDir = RAMDirectory()\n",
    "        analyzer = SmartChineseAnalyzer()\n",
    "        writerConfig = IndexWriterConfig(analyzer)\n",
    "        writerConfig.setOpenMode(IndexWriterConfig.OpenMode.CREATE) # create new directory, remove previously indexed documents\n",
    "        writerConfig.setSimilarity(mySimilarity())\n",
    "        self.indexDir = indexDir\n",
    "        self.writer = IndexWriter(indexDir, writerConfig)\n",
    "\n",
    "    def add(self, pid, ptext):\n",
    "        doc = Document()\n",
    "        doc.add(StringField(\"pid\", pid, Field.Store.YES))\n",
    "        doc.add(TextField(\"ptext\", ptext, Field.Store.YES))\n",
    "        self.writer.addDocument(doc)\n",
    "\t\t\n",
    "    def close(self):\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "myIndexer = ChineseRamIndexer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "myIndexer.add(\"p4\", \"測試\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myIndexer.add(\"p4\", \"測試smar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "myIndexer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParagSearcher:\n",
    "    def __init__(self, indexDir):\n",
    "        lucene.initVM()\n",
    "        analyzer = SmartChineseAnalyzer()\n",
    "        self.reader = DirectoryReader.open(indexDir)\n",
    "        self.searcher = IndexSearcher(self.reader)\n",
    "        self.searcher.setSimilarity(mySimilarity())\n",
    "        self.analyzer = analyzer\n",
    "        logger.info('search similarity:{}'.format(self.searcher.getSimilarity()))\n",
    "        \n",
    "    def search(self, query_text, top_n=1):\n",
    "        query_text = query_text.strip()\n",
    "#         query = QueryParser(\"ptext\", self.analyzer).parse(QueryParser.escape(query_text.strip()))\n",
    "        query = QueryParser(\"ptext\", self.analyzer).parse(query_text)\n",
    "        scoreDocs = self.searcher.search(query, top_n).scoreDocs\n",
    "        \n",
    "        print(scoreDocs)\n",
    "        for scoreDoc in scoreDocs:\n",
    "            docIndex = scoreDoc.doc\n",
    "            doc = self.searcher.doc(docIndex)\n",
    "            print(doc)\n",
    "            print(doc['pid'])\n",
    "            print(self.searcher.explain(query, docIndex))\n",
    "    \n",
    "    def close(self):\n",
    "        self.reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/05/14 15:31:01 ***INFO*** [__main__:9] - search similarity:ClassicSimilarity\n"
     ]
    }
   ],
   "source": [
    "searcher = ParagSearcher(myIndexer.indexDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JArray<object>[<ScoreDoc: doc=0 score=1.4142135 shardIndex=0>]\n",
      "Document<stored,indexed,tokenized,omitNorms,indexOptions=DOCS<pid:p4> stored,indexed,tokenized<ptext:測試>>\n",
      "p4\n",
      "1.4142135 = sum of:\n",
      "  1.4142135 = weight(ptext:試 in 0) [ClassicSimilarity], result of:\n",
      "    1.4142135 = score(freq=1.0), product of:\n",
      "      2.0 = boost\n",
      "      1.0 = idf, computed as log((docCount+1)/(docFreq+1)) + 1 from:\n",
      "        2 = docFreq, number of documents containing term\n",
      "        2 = docCount, total number of documents with field\n",
      "      1.0 = tf(freq=1.0), with freq of:\n",
      "        1.0 = freq, occurrences of term within document\n",
      "      0.70710677 = fieldNorm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searcher.search(\"試試看samr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JArray<object>[<ScoreDoc: doc=0 score=19.79899 shardIndex=0>]\n",
      "p4\n",
      "19.79899 = sum of:\n",
      "  9.899495 = weight(ptext:試 in 0) [ClassicSimilarity], result of:\n",
      "    9.899495 = score(freq=1.0), product of:\n",
      "      14.0 = boost\n",
      "      1.0 = idf, computed as log((docCount+1)/(docFreq+1)) + 1 from:\n",
      "        2 = docFreq, number of documents containing term\n",
      "        2 = docCount, total number of documents with field\n",
      "      1.0 = tf(freq=1.0), with freq of:\n",
      "        1.0 = freq, occurrences of term within document\n",
      "      0.70710677 = fieldNorm\n",
      "  9.899495 = weight(ptext:測 in 0) [ClassicSimilarity], result of:\n",
      "    9.899495 = score(freq=1.0), product of:\n",
      "      14.0 = boost\n",
      "      1.0 = idf, computed as log((docCount+1)/(docFreq+1)) + 1 from:\n",
      "        2 = docFreq, number of documents containing term\n",
      "        2 = docCount, total number of documents with field\n",
      "      1.0 = tf(freq=1.0), with freq of:\n",
      "        1.0 = freq, occurrences of term within document\n",
      "      0.70710677 = fieldNorm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searcher.search(\"測試測試測試測試測試測試測試測試測試測試測試測試測試測試\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JArray<object>[]\n"
     ]
    }
   ],
   "source": [
    "searcher.search(\"smr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JArray<object>[]\n"
     ]
    }
   ],
   "source": [
    "searcher.search(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
